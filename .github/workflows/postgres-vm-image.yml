name: Build PostgreSQL VM Image
on:
  workflow_dispatch:
    inputs:
      flavor:
        description: "Image flavor"
        required: true
        default: standard
        type: choice
        options:
          - standard
          - paradedb
      image_suffix:
        description: "Suffix for image name (e.g., YYYYMMDD.X.Y)"
        type: string
        required: true
      image_resize_gb:
        description: "Target final image size in GB (exact size, not additional space)"
        required: true
        default: 8
        type: number
      build_only:
        description: "âš¡ Build only (skip all uploads) - for testing"
        default: false
        type: boolean
      build_arm64:
        description: "Build ARM64 image (standard flavor only)"
        default: false
        type: boolean
      upload_image:
        description: "ðŸ“¤ Upload to MinIO (ignored if build_only)"
        default: false
        type: boolean
      upload_r2:
        description: "ðŸ“¤ Upload to R2 (ignored if build_only)"
        default: false
        type: boolean
      upload_aws_ami:
        description: "ðŸ“¤ Create AWS AMI (standard flavor only)"
        default: false
        type: boolean
      aws_ami_regions:
        description: "AWS regions for AMI (standard flavor only)"
        type: string
        default: "us-east-1,us-east-2,eu-west-1,ap-southeast-2"
      create_ubicloud_pr:
        description: "ðŸ”„ Create PR to ubicloud/ubicloud with updated image versions"
        default: false
        type: boolean
      test_pr_creation:
        description: "ðŸ§ª TEST ONLY: Skip builds, use dummy values to test PR creation"
        default: false
        type: boolean

jobs:
  # x64 build - always runs (unless test_pr_creation is enabled)
  build-x64:
    name: Build postgres-${{ inputs.flavor }}-ubuntu-2204-x64-${{ inputs.image_suffix }}
    runs-on: ubicloud-standard-4-ubuntu-2204
    if: ${{ !inputs.test_pr_creation }}
    outputs:
      sha256: ${{ steps.compute_sha.outputs.sha256 }}
      all_ami_ids: ${{ steps.copy_ami.outputs.all_ami_ids }}
      source_ami_id: ${{ steps.register_ami.outputs.ami_id }}
    steps:
      - name: Print inputs
        run: |
          echo "Inputs: ${{ toJSON(github.event.inputs) }}"
          echo "Architecture: x64"

      - name: Check out code
        uses: actions/checkout@v3

      - name: Build image
        run: |
          sudo ./build.sh ${{ inputs.flavor }} ${{ inputs.image_resize_gb }}

      - name: Install MinIO client
        run: |
          curl https://dl.min.io/client/mc/release/linux-amd64/mc -o mc
          sudo mv mc /usr/bin/mc
          sudo chmod +x /usr/bin/mc
          mc --version

      - name: Set MinIO root certificates
        run: |
          mkdir -p ~/.mc/certs/CAs
          cat <<EOT > ~/.mc/certs/CAs/ubicloud_images_blob_storage_certs.crt
          ${{ secrets.MINIO_ROOT_CERTIFICATES }}
          EOT

      - name: Set image name output
        id: set_image_name
        run: |
          if [ "${{ inputs.flavor }}" = "standard" ]; then
            image_name=postgres-ubuntu-2204-x64-${{ inputs.image_suffix }}
          else
            image_name=postgres-${{ inputs.flavor }}-ubuntu-2204-x64-${{ inputs.image_suffix }}
          fi
          echo "$image_name"
          echo "MINIO_IMAGE_NAME=$image_name" >> $GITHUB_OUTPUT

      - name: Rename image file and compute SHA256
        id: compute_sha
        run: |
          image_filename=${{ steps.set_image_name.outputs.MINIO_IMAGE_NAME }}.raw
          sha_filename=${{ steps.set_image_name.outputs.MINIO_IMAGE_NAME }}.raw.sha256
          mv postgres-${{ inputs.flavor }}-x64-image.raw ${image_filename}
          sha256sum ${image_filename} > ${sha_filename}
          sha256=$(cut -d' ' -f1 ${sha_filename})
          echo "sha256=${sha256}" >> $GITHUB_OUTPUT
          echo "### Image (x64)" >> $GITHUB_STEP_SUMMARY
          du -h ${image_filename} >> $GITHUB_STEP_SUMMARY
          echo "### Image SHA256" >> $GITHUB_STEP_SUMMARY
          cat ${sha_filename} >> $GITHUB_STEP_SUMMARY

      - name: Upload to MinIO
        if: ${{ inputs.upload_image && !inputs.build_only }}
        env:
          MC_HOST_ubicloud: ${{ secrets.MINIO_CONNECTION_STRING }}
        run: |
          image_filename=${{ steps.set_image_name.outputs.MINIO_IMAGE_NAME }}.raw
          sha_filename=${{ steps.set_image_name.outputs.MINIO_IMAGE_NAME }}.raw.sha256

          mc cp ./${image_filename} ubicloud/ubicloud-images/${image_filename}
          mc cp ./${sha_filename} ubicloud/ubicloud-images/${sha_filename}

      - name: Upload to R2
        if: ${{ inputs.upload_r2 == true && !inputs.build_only }}
        env:
          R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_BUCKET: ${{ secrets.R2_BUCKET }}
        run: |
          if [ -z "${R2_BUCKET}" ] || [ -z "${R2_ENDPOINT}" ]; then
            echo "R2 secrets not configured, skipping R2 upload"
            exit 0
          fi

          # Set up mc alias for R2
          mc alias set r2 "${R2_ENDPOINT}" "${R2_ACCESS_KEY_ID}" "${R2_SECRET_ACCESS_KEY}"

          image_filename=${{ steps.set_image_name.outputs.MINIO_IMAGE_NAME }}.raw
          sha_filename=${{ steps.set_image_name.outputs.MINIO_IMAGE_NAME }}.raw.sha256

          echo "Uploading to R2..."
          mc cp ./${image_filename} r2/${R2_BUCKET}/${image_filename}
          mc cp ./${sha_filename} r2/${R2_BUCKET}/${sha_filename}

          echo "### R2 Upload" >> $GITHUB_STEP_SUMMARY
          echo "Uploaded to R2" >> $GITHUB_STEP_SUMMARY

      - name: Install AWS CLI
        if: ${{ inputs.upload_aws_ami && inputs.flavor == 'standard' && !inputs.build_only }}
        run: |
          curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
          unzip -q awscliv2.zip
          sudo ./aws/install --update
          aws --version

      - name: Upload image to S3
        if: ${{ inputs.upload_aws_ami && inputs.flavor == 'standard' && !inputs.build_only }}
        id: s3_upload
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-west-2
        run: |
          image_filename=${{ steps.set_image_name.outputs.MINIO_IMAGE_NAME }}.raw
          s3_bucket=${{ secrets.AWS_S3_BUCKET }}

          echo "Uploading image to S3..."
          aws s3 cp ./${image_filename} s3://${s3_bucket}/${image_filename}

          echo "image_filename=${image_filename}" >> $GITHUB_OUTPUT
          echo "s3_bucket=${s3_bucket}" >> $GITHUB_OUTPUT

      - name: Import snapshot to AWS
        if: ${{ inputs.upload_aws_ami && inputs.flavor == 'standard' && !inputs.build_only }}
        id: import_snapshot
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-west-2
        run: |
          image_filename=${{ steps.s3_upload.outputs.image_filename }}
          s3_bucket=${{ steps.s3_upload.outputs.s3_bucket }}

          cat <<EOT > containers.json
          {
            "Description": "${image_filename}",
            "Format": "raw",
            "UserBucket": {
              "S3Bucket": "${s3_bucket}",
              "S3Key": "${image_filename}"
            }
          }
          EOT

          echo "Starting snapshot import..."
          import_task_id=$(aws ec2 import-snapshot \
            --description "${image_filename}" \
            --disk-container file://containers.json \
            --query "ImportTaskId" \
            --output text)

          echo "Import task ID: ${import_task_id}"
          echo "import_task_id=${import_task_id}" >> $GITHUB_OUTPUT

      - name: Wait for snapshot import completion
        if: ${{ inputs.upload_aws_ami && inputs.flavor == 'standard' && !inputs.build_only }}
        id: wait_snapshot
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-west-2
        run: |
          import_task_id=${{ steps.import_snapshot.outputs.import_task_id }}

          while true; do
            status=$(aws ec2 describe-import-snapshot-tasks \
              --import-task-ids "${import_task_id}" \
              --query "ImportSnapshotTasks[0].SnapshotTaskDetail.Status" \
              --output text)
            progress=$(aws ec2 describe-import-snapshot-tasks \
              --import-task-ids "${import_task_id}" \
              --query "ImportSnapshotTasks[0].SnapshotTaskDetail.Progress" \
              --output text 2>/dev/null || echo "N/A")

            echo "Status: ${status}, Progress: ${progress}%"

            if [ "${status}" = "completed" ]; then
              echo "Snapshot import completed successfully."
              break
            elif [ "${status}" = "cancelled" ] || [ "${status}" = "failed" ]; then
              echo "Snapshot import failed!"
              aws ec2 describe-import-snapshot-tasks --import-task-ids "${import_task_id}"
              exit 1
            fi

            sleep 20
          done

          snapshot_id=$(aws ec2 describe-import-snapshot-tasks \
            --import-task-ids "${import_task_id}" \
            --query "ImportSnapshotTasks[0].SnapshotTaskDetail.SnapshotId" \
            --output text)

          echo "Snapshot ID: ${snapshot_id}"
          echo "snapshot_id=${snapshot_id}" >> $GITHUB_OUTPUT

      - name: Register AMI from snapshot
        if: ${{ inputs.upload_aws_ami && inputs.flavor == 'standard' && !inputs.build_only }}
        id: register_ami
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-west-2
        run: |
          ami_name=${{ steps.set_image_name.outputs.MINIO_IMAGE_NAME }}
          snapshot_id=${{ steps.wait_snapshot.outputs.snapshot_id }}

          ami_id=$(aws ec2 register-image \
            --name "${ami_name}" \
            --architecture x86_64 \
            --virtualization-type hvm \
            --ena-support \
            --root-device-name /dev/sda1 \
            --block-device-mappings "[{\"DeviceName\":\"/dev/sda1\",\"Ebs\":{\"SnapshotId\":\"${snapshot_id}\",\"VolumeSize\":${{ inputs.image_resize_gb }}}}]" \
            --query "ImageId" \
            --output text)

          echo "Registered AMI: ${ami_id}"
          echo "ami_id=${ami_id}" >> $GITHUB_OUTPUT

          aws ec2 create-tags \
            --resources ${ami_id} \
            --tags Key=Name,Value=${ami_name} Key=Source,Value=postgres-vm-images Key=Architecture,Value=x64

          echo "### AWS AMI (x64)" >> $GITHUB_STEP_SUMMARY
          echo "AMI ID: ${ami_id}" >> $GITHUB_STEP_SUMMARY
          echo "AMI Name: ${ami_name}" >> $GITHUB_STEP_SUMMARY
          echo "Architecture: x86_64" >> $GITHUB_STEP_SUMMARY
          echo "Snapshot ID: ${snapshot_id}" >> $GITHUB_STEP_SUMMARY
          echo "Region: us-west-2" >> $GITHUB_STEP_SUMMARY

      - name: Copy AMI to additional regions
        if: ${{ inputs.upload_aws_ami && inputs.flavor == 'standard' && inputs.aws_ami_regions != '' && !inputs.build_only }}
        id: copy_ami
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-west-2
        run: |
          ami_id=${{ steps.register_ami.outputs.ami_id }}
          ami_name=${{ steps.set_image_name.outputs.MINIO_IMAGE_NAME }}
          regions="${{ inputs.aws_ami_regions }}"

          echo "Copying AMI ${ami_id} to additional regions: ${regions}"
          echo "### AMI Copies (x64)" >> $GITHUB_STEP_SUMMARY

          # Store all AMI IDs for making public later
          all_ami_ids="us-west-2:${ami_id}"

          IFS=',' read -ra REGION_ARRAY <<< "$regions"
          for region in "${REGION_ARRAY[@]}"; do
            region=$(echo "$region" | xargs)
            echo "Copying to ${region}..."

            copied_ami_id=$(aws ec2 copy-image \
              --source-region us-west-2 \
              --source-image-id "${ami_id}" \
              --name "${ami_name}" \
              --region "${region}" \
              --query "ImageId" \
              --output text)

            echo "Copied AMI to ${region}: ${copied_ami_id}"
            echo "- ${region}: ${copied_ami_id}" >> $GITHUB_STEP_SUMMARY
            all_ami_ids="${all_ami_ids},${region}:${copied_ami_id}"

            aws ec2 create-tags \
              --resources ${copied_ami_id} \
              --tags Key=Name,Value=${ami_name} Key=Source,Value=postgres-vm-images Key=Architecture,Value=x64 \
              --region "${region}"
          done

          echo "all_ami_ids=${all_ami_ids}" >> $GITHUB_OUTPUT

      - name: Wait for AMI copies and make public
        if: ${{ inputs.upload_aws_ami && inputs.flavor == 'standard' && !inputs.build_only }}
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          ami_id=${{ steps.register_ami.outputs.ami_id }}
          all_ami_ids="${{ steps.copy_ami.outputs.all_ami_ids }}"

          # If no copies were made, just use the source AMI
          if [ -z "$all_ami_ids" ]; then
            all_ami_ids="us-west-2:${ami_id}"
          fi

          echo "Waiting for AMIs to become available and making them public..."
          echo "### Public AMIs (x64)" >> $GITHUB_STEP_SUMMARY

          IFS=',' read -ra AMI_ARRAY <<< "$all_ami_ids"
          for entry in "${AMI_ARRAY[@]}"; do
            region=$(echo "$entry" | cut -d: -f1)
            ami=$(echo "$entry" | cut -d: -f2)

            echo "Waiting for ${ami} in ${region}..."

            # Wait for AMI to be available (max 10 minutes)
            for i in {1..30}; do
              state=$(aws ec2 describe-images --image-ids "${ami}" --region "${region}" --query 'Images[0].State' --output text 2>/dev/null || echo "pending")
              if [ "$state" = "available" ]; then
                echo "AMI ${ami} is available in ${region}"
                break
              fi
              echo "  State: ${state}, waiting..."
              sleep 20
            done

            # Make AMI public
            echo "Making ${ami} public in ${region}..."
            aws ec2 modify-image-attribute \
              --image-id "${ami}" \
              --launch-permission "Add=[{Group=all}]" \
              --region "${region}"

            echo "- ${region}: ${ami} (public)" >> $GITHUB_STEP_SUMMARY
          done

      - name: Clean up S3
        if: ${{ inputs.upload_aws_ami && inputs.flavor == 'standard' && !inputs.build_only }}
        continue-on-error: true
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-west-2
        run: |
          echo "Cleaning up S3..."
          aws s3 rm s3://${{ steps.s3_upload.outputs.s3_bucket }}/${{ steps.s3_upload.outputs.image_filename }}

  # arm64 build - only runs for standard flavor
  build-arm64:
    name: Build postgres-${{ inputs.flavor }}-ubuntu-2204-arm64-${{ inputs.image_suffix }}
    runs-on: ubicloud-standard-4-arm-ubuntu-2204
    if: ${{ !inputs.test_pr_creation && inputs.flavor == 'standard' && (inputs.build_arm64 || (inputs.upload_aws_ami && !inputs.build_only)) }}
    outputs:
      sha256: ${{ steps.compute_sha.outputs.sha256 }}
      all_ami_ids: ${{ steps.copy_ami.outputs.all_ami_ids }}
      source_ami_id: ${{ steps.register_ami.outputs.ami_id }}
    steps:
      - name: Print inputs
        run: |
          echo "Inputs: ${{ toJSON(github.event.inputs) }}"
          echo "Architecture: arm64"

      - name: Check out code
        uses: actions/checkout@v3

      - name: Build image
        run: |
          sudo ./build.sh ${{ inputs.flavor }} ${{ inputs.image_resize_gb }}

      - name: Set image name output
        id: set_image_name
        run: |
          image_name=postgres-ubuntu-2204-arm64-${{ inputs.image_suffix }}
          echo "$image_name"
          echo "IMAGE_NAME=$image_name" >> $GITHUB_OUTPUT

      - name: Rename image file and compute SHA256
        id: compute_sha
        run: |
          image_filename=${{ steps.set_image_name.outputs.IMAGE_NAME }}.raw
          sha_filename=${{ steps.set_image_name.outputs.IMAGE_NAME }}.raw.sha256
          mv postgres-standard-arm64-image.raw ${image_filename}
          sha256sum ${image_filename} > ${sha_filename}
          sha256=$(cut -d' ' -f1 ${sha_filename})
          echo "sha256=${sha256}" >> $GITHUB_OUTPUT
          echo "### Image (arm64)" >> $GITHUB_STEP_SUMMARY
          du -h ${image_filename} >> $GITHUB_STEP_SUMMARY
          echo "### Image SHA256" >> $GITHUB_STEP_SUMMARY
          cat ${sha_filename} >> $GITHUB_STEP_SUMMARY

      - name: Install AWS CLI
        if: ${{ !inputs.build_only }}
        run: |
          curl "https://awscli.amazonaws.com/awscli-exe-linux-aarch64.zip" -o "awscliv2.zip"
          unzip -q awscliv2.zip
          sudo ./aws/install --update
          aws --version

      - name: Upload image to S3
        if: ${{ !inputs.build_only }}
        id: s3_upload
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-west-2
        run: |
          image_filename=${{ steps.set_image_name.outputs.IMAGE_NAME }}.raw
          s3_bucket=${{ secrets.AWS_S3_BUCKET }}

          echo "Uploading image to S3..."
          aws s3 cp ./${image_filename} s3://${s3_bucket}/${image_filename}

          echo "image_filename=${image_filename}" >> $GITHUB_OUTPUT
          echo "s3_bucket=${s3_bucket}" >> $GITHUB_OUTPUT

      - name: Import snapshot to AWS
        if: ${{ !inputs.build_only }}
        id: import_snapshot
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-west-2
        run: |
          image_filename=${{ steps.s3_upload.outputs.image_filename }}
          s3_bucket=${{ steps.s3_upload.outputs.s3_bucket }}

          cat <<EOT > containers.json
          {
            "Description": "${image_filename}",
            "Format": "raw",
            "UserBucket": {
              "S3Bucket": "${s3_bucket}",
              "S3Key": "${image_filename}"
            }
          }
          EOT

          echo "Starting snapshot import..."
          import_task_id=$(aws ec2 import-snapshot \
            --description "${image_filename}" \
            --disk-container file://containers.json \
            --query "ImportTaskId" \
            --output text)

          echo "Import task ID: ${import_task_id}"
          echo "import_task_id=${import_task_id}" >> $GITHUB_OUTPUT

      - name: Wait for snapshot import completion
        if: ${{ !inputs.build_only }}
        id: wait_snapshot
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-west-2
        run: |
          import_task_id=${{ steps.import_snapshot.outputs.import_task_id }}

          while true; do
            status=$(aws ec2 describe-import-snapshot-tasks \
              --import-task-ids "${import_task_id}" \
              --query "ImportSnapshotTasks[0].SnapshotTaskDetail.Status" \
              --output text)
            progress=$(aws ec2 describe-import-snapshot-tasks \
              --import-task-ids "${import_task_id}" \
              --query "ImportSnapshotTasks[0].SnapshotTaskDetail.Progress" \
              --output text 2>/dev/null || echo "N/A")

            echo "Status: ${status}, Progress: ${progress}%"

            if [ "${status}" = "completed" ]; then
              echo "Snapshot import completed successfully."
              break
            elif [ "${status}" = "cancelled" ] || [ "${status}" = "failed" ]; then
              echo "Snapshot import failed!"
              aws ec2 describe-import-snapshot-tasks --import-task-ids "${import_task_id}"
              exit 1
            fi

            sleep 20
          done

          snapshot_id=$(aws ec2 describe-import-snapshot-tasks \
            --import-task-ids "${import_task_id}" \
            --query "ImportSnapshotTasks[0].SnapshotTaskDetail.SnapshotId" \
            --output text)

          echo "Snapshot ID: ${snapshot_id}"
          echo "snapshot_id=${snapshot_id}" >> $GITHUB_OUTPUT

      - name: Register AMI from snapshot
        if: ${{ !inputs.build_only }}
        id: register_ami
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-west-2
        run: |
          ami_name=${{ steps.set_image_name.outputs.IMAGE_NAME }}
          snapshot_id=${{ steps.wait_snapshot.outputs.snapshot_id }}

          ami_id=$(aws ec2 register-image \
            --name "${ami_name}" \
            --architecture arm64 \
            --virtualization-type hvm \
            --ena-support \
            --root-device-name /dev/sda1 \
            --block-device-mappings "[{\"DeviceName\":\"/dev/sda1\",\"Ebs\":{\"SnapshotId\":\"${snapshot_id}\",\"VolumeSize\":${{ inputs.image_resize_gb }}}}]" \
            --query "ImageId" \
            --output text)

          echo "Registered AMI: ${ami_id}"
          echo "ami_id=${ami_id}" >> $GITHUB_OUTPUT

          aws ec2 create-tags \
            --resources ${ami_id} \
            --tags Key=Name,Value=${ami_name} Key=Source,Value=postgres-vm-images Key=Architecture,Value=arm64

          echo "### AWS AMI (arm64)" >> $GITHUB_STEP_SUMMARY
          echo "AMI ID: ${ami_id}" >> $GITHUB_STEP_SUMMARY
          echo "AMI Name: ${ami_name}" >> $GITHUB_STEP_SUMMARY
          echo "Architecture: arm64" >> $GITHUB_STEP_SUMMARY
          echo "Snapshot ID: ${snapshot_id}" >> $GITHUB_STEP_SUMMARY
          echo "Region: us-west-2" >> $GITHUB_STEP_SUMMARY

      - name: Copy AMI to additional regions
        if: ${{ inputs.aws_ami_regions != '' && !inputs.build_only }}
        id: copy_ami
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-west-2
        run: |
          ami_id=${{ steps.register_ami.outputs.ami_id }}
          ami_name=${{ steps.set_image_name.outputs.IMAGE_NAME }}
          regions="${{ inputs.aws_ami_regions }}"

          echo "Copying AMI ${ami_id} to additional regions: ${regions}"
          echo "### AMI Copies (arm64)" >> $GITHUB_STEP_SUMMARY

          # Store all AMI IDs for making public later
          all_ami_ids="us-west-2:${ami_id}"

          IFS=',' read -ra REGION_ARRAY <<< "$regions"
          for region in "${REGION_ARRAY[@]}"; do
            region=$(echo "$region" | xargs)
            echo "Copying to ${region}..."

            copied_ami_id=$(aws ec2 copy-image \
              --source-region us-west-2 \
              --source-image-id "${ami_id}" \
              --name "${ami_name}" \
              --region "${region}" \
              --query "ImageId" \
              --output text)

            echo "Copied AMI to ${region}: ${copied_ami_id}"
            echo "- ${region}: ${copied_ami_id}" >> $GITHUB_STEP_SUMMARY
            all_ami_ids="${all_ami_ids},${region}:${copied_ami_id}"

            aws ec2 create-tags \
              --resources ${copied_ami_id} \
              --tags Key=Name,Value=${ami_name} Key=Source,Value=postgres-vm-images Key=Architecture,Value=arm64 \
              --region "${region}"
          done

          echo "all_ami_ids=${all_ami_ids}" >> $GITHUB_OUTPUT

      - name: Wait for AMI copies and make public
        if: ${{ !inputs.build_only }}
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          ami_id=${{ steps.register_ami.outputs.ami_id }}
          all_ami_ids="${{ steps.copy_ami.outputs.all_ami_ids }}"

          # If no copies were made, just use the source AMI
          if [ -z "$all_ami_ids" ]; then
            all_ami_ids="us-west-2:${ami_id}"
          fi

          echo "Waiting for AMIs to become available and making them public..."
          echo "### Public AMIs (arm64)" >> $GITHUB_STEP_SUMMARY

          IFS=',' read -ra AMI_ARRAY <<< "$all_ami_ids"
          for entry in "${AMI_ARRAY[@]}"; do
            region=$(echo "$entry" | cut -d: -f1)
            ami=$(echo "$entry" | cut -d: -f2)

            echo "Waiting for ${ami} in ${region}..."

            # Wait for AMI to be available (max 10 minutes)
            for i in {1..30}; do
              state=$(aws ec2 describe-images --image-ids "${ami}" --region "${region}" --query 'Images[0].State' --output text 2>/dev/null || echo "pending")
              if [ "$state" = "available" ]; then
                echo "AMI ${ami} is available in ${region}"
                break
              fi
              echo "  State: ${state}, waiting..."
              sleep 20
            done

            # Make AMI public
            echo "Making ${ami} public in ${region}..."
            aws ec2 modify-image-attribute \
              --image-id "${ami}" \
              --launch-permission "Add=[{Group=all}]" \
              --region "${region}"

            echo "- ${region}: ${ami} (public)" >> $GITHUB_STEP_SUMMARY
          done

      - name: Clean up S3
        if: ${{ !inputs.build_only }}
        continue-on-error: true
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-west-2
        run: |
          echo "Cleaning up S3..."
          aws s3 rm s3://${{ steps.s3_upload.outputs.s3_bucket }}/${{ steps.s3_upload.outputs.image_filename }}

  # Create PR to ubicloud/ubicloud with updated image versions
  create-ubicloud-pr:
    name: Create PR to ubicloud/ubicloud
    runs-on: ubicloud-standard-2-ubuntu-2204
    needs: [build-x64, build-arm64]
    if: ${{ always() && (inputs.test_pr_creation || (inputs.create_ubicloud_pr && !inputs.build_only && needs.build-x64.result == 'success')) }}
    steps:
      - name: Collect build outputs
        id: collect
        run: |
          # Determine image name for download_boot_image.rb
          if [ "${{ inputs.flavor }}" = "standard" ]; then
            image_name="postgres-ubuntu-2204"
          else
            image_name="postgres-${{ inputs.flavor }}-ubuntu-2204"
          fi
          echo "image_name=${image_name}" >> $GITHUB_OUTPUT
          echo "version=${{ inputs.image_suffix }}" >> $GITHUB_OUTPUT

          # Check if running in test mode
          if [ "${{ inputs.test_pr_creation }}" = "true" ]; then
            echo "ðŸ§ª TEST MODE: Using dummy values"
            echo "x64_sha256=dummy_x64_sha256_for_testing_0123456789abcdef" >> $GITHUB_OUTPUT
            echo "arm64_sha256=dummy_arm64_sha256_for_testing_fedcba9876543210" >> $GITHUB_OUTPUT
            echo "x64_ami_ids=us-west-2:ami-test-x64-uswest2,us-east-1:ami-test-x64-useast1" >> $GITHUB_OUTPUT
            echo "arm64_ami_ids=us-west-2:ami-test-arm64-uswest2,us-east-1:ami-test-arm64-useast1" >> $GITHUB_OUTPUT
          else
            # x64 data
            echo "x64_sha256=${{ needs.build-x64.outputs.sha256 }}" >> $GITHUB_OUTPUT

            # arm64 data (may be empty if arm64 job didn't run)
            echo "arm64_sha256=${{ needs.build-arm64.outputs.sha256 }}" >> $GITHUB_OUTPUT

            # AMI IDs
            x64_amis="${{ needs.build-x64.outputs.all_ami_ids }}"
            if [ -z "$x64_amis" ] && [ -n "${{ needs.build-x64.outputs.source_ami_id }}" ]; then
              x64_amis="us-west-2:${{ needs.build-x64.outputs.source_ami_id }}"
            fi
            echo "x64_ami_ids=${x64_amis}" >> $GITHUB_OUTPUT

            arm64_amis="${{ needs.build-arm64.outputs.all_ami_ids }}"
            if [ -z "$arm64_amis" ] && [ -n "${{ needs.build-arm64.outputs.source_ami_id }}" ]; then
              arm64_amis="us-west-2:${{ needs.build-arm64.outputs.source_ami_id }}"
            fi
            echo "arm64_ami_ids=${arm64_amis}" >> $GITHUB_OUTPUT
          fi

      - name: Clone ubicloud/ubicloud
        run: |
          git clone --depth 1 https://github.com/ubicloud/ubicloud.git ubicloud

      - name: Update download_boot_image.rb
        run: |
          cd ubicloud
          image_name="${{ steps.collect.outputs.image_name }}"
          version="${{ steps.collect.outputs.version }}"
          x64_sha="${{ steps.collect.outputs.x64_sha256 }}"
          arm64_sha="${{ steps.collect.outputs.arm64_sha256 }}"

          # Find and replace existing entries for this image (update version AND sha)
          # Pattern: ["image-name", "arch", "old-version"] => "old-sha",
          if [ -n "$x64_sha" ]; then
            # Replace the existing x64 entry with new version and sha
            sed -i -E "s|\\[\"${image_name}\", \"x64\", \"[^\"]+\"\\] => \"[^\"]+\"|[\"${image_name}\", \"x64\", \"${version}\"] => \"${x64_sha}\"|" prog/download_boot_image.rb
            echo "Updated x64 entry: ${image_name} -> ${version}"
          fi

          if [ -n "$arm64_sha" ]; then
            # Replace the existing arm64 entry with new version and sha
            sed -i -E "s|\\[\"${image_name}\", \"arm64\", \"[^\"]+\"\\] => \"[^\"]+\"|[\"${image_name}\", \"arm64\", \"${version}\"] => \"${arm64_sha}\"|" prog/download_boot_image.rb
            echo "Updated arm64 entry: ${image_name} -> ${version}"
          fi

          # Show the changes
          echo "=== Updated entries ==="
          grep "${image_name}" prog/download_boot_image.rb || true

      - name: Create migration file
        if: ${{ inputs.flavor == 'standard' }}
        run: |
          cd ubicloud
          timestamp=$(date +%Y%m%d)
          migration_file="migrate/${timestamp}_update_pg_${{ inputs.flavor }}_amis.rb"

          x64_amis="${{ steps.collect.outputs.x64_ami_ids }}"
          arm64_amis="${{ steps.collect.outputs.arm64_ami_ids }}"

          # Find old AMIs from previous migration files (keyed by region:arch)
          declare -A old_amis
          echo "=== Searching for existing AMIs in migration files ==="
          for migration in $(ls -1 migrate/*.rb 2>/dev/null | sort); do
            # Match ["region", "arch", "ami-..."] or ["region", "arch", "ami-...", "ami-..."]
            while IFS= read -r match; do
              region=$(echo "$match" | sed -E 's/.*\["([^"]+)".*/\1/')
              arch=$(echo "$match" | sed -E 's/.*",\s*"(x64|arm64)".*/\1/')
              ami=$(echo "$match" | sed -E 's/.*",\s*"(x64|arm64)",\s*"(ami-[^"]+)".*/\2/')
              if [[ "$ami" =~ ^ami- ]]; then
                old_amis["${region}:${arch}"]="$ami"
              fi
            done < <(grep -oE '\["[^"]+",\s*"(x64|arm64)",\s*"ami-[^"]+"' "$migration" 2>/dev/null || true)
          done

          echo "Found ${#old_amis[@]} existing AMI entries"

          # Collect entries: [region, arch, new_ami, old_ami]
          entries=()

          if [ -n "$x64_amis" ]; then
            IFS=',' read -ra AMI_ARRAY <<< "$x64_amis"
            for entry in "${AMI_ARRAY[@]}"; do
              region=$(echo "$entry" | cut -d: -f1)
              new_ami=$(echo "$entry" | cut -d: -f2)
              old_ami="${old_amis["${region}:x64"]:-}"
              entries+=("    [\"${region}\", \"x64\", \"${new_ami}\", \"${old_ami}\"]")
            done
          fi

          if [ -n "$arm64_amis" ]; then
            IFS=',' read -ra AMI_ARRAY <<< "$arm64_amis"
            for entry in "${AMI_ARRAY[@]}"; do
              region=$(echo "$entry" | cut -d: -f1)
              new_ami=$(echo "$entry" | cut -d: -f2)
              old_ami="${old_amis["${region}:arm64"]:-}"
              entries+=("    [\"${region}\", \"arm64\", \"${new_ami}\", \"${old_ami}\"]")
            done
          fi

          # Build the migration file
          cat > "${migration_file}" << 'MIGRATION_HEADER'
          # frozen_string_literal: true

          Sequel.migration do
            ami_ids = [
          MIGRATION_HEADER

          # Remove leading spaces from heredoc
          sed -i 's/^          //' "${migration_file}"

          # Write entries with proper comma separation
          total=${#entries[@]}
          for i in "${!entries[@]}"; do
            if [ $i -eq $((total - 1)) ]; then
              echo "${entries[$i]}" >> "${migration_file}"
            else
              echo "${entries[$i]}," >> "${migration_file}"
            fi
          done

          cat >> "${migration_file}" << 'MIGRATION_FOOTER'
            ]

            up do
              ami_ids.each do |location_name, arch, new_ami, old_ami|
                from(:pg_aws_ami)
                  .where(aws_location_name: location_name, arch:, aws_ami_id: old_ami)
                  .update(aws_ami_id: new_ami)
              end
            end

            down do
              ami_ids.each do |location_name, arch, new_ami, old_ami|
                from(:pg_aws_ami)
                  .where(aws_location_name: location_name, arch:, aws_ami_id: new_ami)
                  .update(aws_ami_id: old_ami)
              end
            end
          end
          MIGRATION_FOOTER

          # Remove leading spaces from heredoc
          sed -i 's/^          //' "${migration_file}"

          echo "Created migration file: ${migration_file}"
          cat "${migration_file}"

      - name: Create Pull Request
        env:
          GH_TOKEN: ${{ secrets.UBICLOUD_REPO_PAT }}
        run: |
          cd ubicloud

          # Configure git
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Configure git to use the PAT for authentication
          git remote set-url origin "https://x-access-token:${GH_TOKEN}@github.com/ubicloud/ubicloud.git"

          branch_name="update-postgres-${{ inputs.flavor }}-images-${{ inputs.image_suffix }}"

          # Check if PR already exists for this branch
          existing_pr=$(gh pr list --repo ubicloud/ubicloud --head "${branch_name}" --json number -q '.[0].number' 2>/dev/null || echo "")
          if [ -n "$existing_pr" ]; then
            echo "PR #${existing_pr} already exists for branch ${branch_name}"
            echo "### Existing PR" >> $GITHUB_STEP_SUMMARY
            gh pr view --repo ubicloud/ubicloud "${existing_pr}" --json url -q '.url' >> $GITHUB_STEP_SUMMARY
            exit 0
          fi

          # Delete remote branch if it exists (from failed previous run)
          git push origin --delete "${branch_name}" 2>/dev/null || true

          # Create branch and commit
          git checkout -b "${branch_name}"
          git add -A
          git commit -m "Update postgres-${{ inputs.flavor }} images to ${{ inputs.image_suffix }}"

          # Push branch
          git push -u origin "${branch_name}"

          # Create PR
          gh pr create \
            --repo ubicloud/ubicloud \
            --head "${branch_name}" \
            --title "Update postgres-${{ inputs.flavor }} images to ${{ inputs.image_suffix }}" \
            --body "## Summary
          - Updates boot image SHA256 hashes in \`prog/download_boot_image.rb\`
          - Adds migration to insert AWS AMI IDs in \`pg_aws_ami\` table

          ## Image Version
          \`${{ inputs.image_suffix }}\`

          ## Changes
          - x64 SHA256: \`${{ steps.collect.outputs.x64_sha256 }}\`
          - arm64 SHA256: \`${{ steps.collect.outputs.arm64_sha256 }}\`

          ðŸ¤– Generated by [postgres-vm-images](https://github.com/ubicloud/postgres-vm-images) workflow"

          echo "### PR Created" >> $GITHUB_STEP_SUMMARY
          gh pr view --repo ubicloud/ubicloud "${branch_name}" --json url -q '.url' >> $GITHUB_STEP_SUMMARY
